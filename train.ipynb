{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import argparse\n",
    "import time\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from model import CycleGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa.display\n",
    "from IPython.display import Audio\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "rcParams['figure.figsize'] = (16, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_A_dir = '/media/jg/H/data/VCC2016/vcc2016_training/SF1'\n",
    "# train_B_dir = '/media/jg/H/data/VCC2016/vcc2016_training/TM2'\n",
    "# validation_A_dir = '/media/jg/H/data/VCC2016/evaluation_all/SF1'\n",
    "# validation_B_dir = '/media/jg/H/data/VCC2016/evaluation_all/TM2'\n",
    "\n",
    "train_A_dir = './../../../Database/Emotion/hap_neu/hap'\n",
    "train_B_dir = './../../../Database/Emotion/hap_neu/neu'\n",
    "validation_A_dir = './../../../Database/Emotion/hap_neu/val_hap'\n",
    "validation_B_dir = './../../../Database/Emotion/hap_neu/val_neu'\n",
    "model_name = 'hap2neu.ckpt'\n",
    "model_dir = './model/hap2neu'\n",
    "output_dir = './validation_output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 0\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set training parameters\n",
    "num_epochs = 5000\n",
    "mini_batch_size = 1 # mini_batch_size = 1 is better\n",
    "generator_learning_rate = 0.0002\n",
    "generator_learning_rate_decay = generator_learning_rate / 200000\n",
    "discriminator_learning_rate = 0.0001\n",
    "discriminator_learning_rate_decay = discriminator_learning_rate / 200000\n",
    "sampling_rate = 16000\n",
    "num_mcep = 24\n",
    "frame_period = 5.0\n",
    "n_frames = 128\n",
    "lambda_cycle = 10\n",
    "lambda_identity = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load audio waveform\n",
    "wavs_A = load_wavs(wav_dir = train_A_dir, sr = sampling_rate)\n",
    "wavs_B = load_wavs(wav_dir = train_B_dir, sr = sampling_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = wavs_A[1]\n",
    "print(np.shape(x))\n",
    "librosa.display.waveplot(x, sr=sampling_rate)\n",
    "Audio(x, rate=sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract Pitch contour (f0s), Harmonic spectral envelope (sps) and Aperiodic spectral envelope (aps)\n",
    "f0s_A, timeaxes_A, sps_A, aps_A, coded_sps_A = world_encode_data(wavs = wavs_A, fs = sampling_rate, frame_period = frame_period, coded_dim = num_mcep)\n",
    "f0s_B, timeaxes_B, sps_B, aps_B, coded_sps_B = world_encode_data(wavs = wavs_B, fs = sampling_rate, frame_period = frame_period, coded_dim = num_mcep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare for log Gaussian Normalized Transform \n",
    "log_f0s_mean_A, log_f0s_std_A = logf0_statistics(f0s_A)\n",
    "log_f0s_mean_B, log_f0s_std_B = logf0_statistics(f0s_B)\n",
    "print('log f0 of Pitch A: Mean %f, Std %f' %(log_f0s_mean_A, log_f0s_std_A))\n",
    "print('log f0 of Pitch B: Mean %f, Std %f' %(log_f0s_mean_B, log_f0s_std_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coded_sps_A_transposed = transpose_in_list(lst = coded_sps_A)\n",
    "coded_sps_B_transposed = transpose_in_list(lst = coded_sps_B)\n",
    "coded_sps_A_norm, coded_sps_A_mean, coded_sps_A_std = coded_sps_normalization_fit_transoform(coded_sps = coded_sps_A_transposed)\n",
    "coded_sps_B_norm, coded_sps_B_mean, coded_sps_B_std = coded_sps_normalization_fit_transoform(coded_sps = coded_sps_B_transposed)\n",
    "print(\"Input data fixed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "x = wavs_A[idx]\n",
    "print(np.shape(x))\n",
    "librosa.display.waveplot(x, sr=sampling_rate)\n",
    "Audio(x, rate=sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(f0s_A[0])\n",
    "title('F0')\n",
    "plt.xlabel('Frame')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHECK preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(coded_sps_A_norm), np.shape(coded_sps_A_norm[0]))\n",
    "print(len(coded_sps_B_norm), np.shape(coded_sps_B_norm[0]))\n",
    "pool_A, pool_B, f0sA, f0sB  = list(coded_sps_A_norm), list(coded_sps_B_norm), list(f0s_A), list(f0s_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample proportional to the length\n",
    "def sample_train_data2(pool_A, pool_B, f0s_A, f0s_B, n_frames=128, max_samples=1000):\n",
    "\n",
    "#     np.random.shuffle(pool_A)\n",
    "#     np.random.shuffle(pool_B)\n",
    "    \n",
    "    train_data_A = []\n",
    "    train_data_B = []\n",
    "    \n",
    "    while pool_A and pool_B:\n",
    "        \n",
    "        idx_A = np.random.randint(len(pool_A))\n",
    "        idx_B = np.random.randint(len(pool_B))\n",
    "        data_A, data_B = pool_A[idx_A], pool_B[idx_B]\n",
    "        data_A_len, data_B_len = data_A.shape[1], data_B.shape[1]   \n",
    "        f0_A, f0_B = f0s_A[idx_A], f0s_B[idx_B]\n",
    "        \n",
    "        if data_A_len < n_frames:\n",
    "            del pool_A[idx_A]\n",
    "            del f0s_A[idx_A]\n",
    "            continue\n",
    "        \n",
    "        if data_B_len < n_frames:\n",
    "            del pool_B[idx_B]\n",
    "            del f0s_B[idx_B]\n",
    "            continue\n",
    "            \n",
    "        start_A = np.random.randint(data_A_len - n_frames + 1)\n",
    "        end_A = start_A + n_frames\n",
    "        if max(f0_A[start_A:end_A]) > 0:\n",
    "            train_data_A.append(data_A[:,start_A:end_A])\n",
    "        if start_A >= n_frames and max(f0_A[0:start_A]) > 0:\n",
    "            pool_A.append(data_A[:,0:start_A])\n",
    "            f0s_A.append(f0_A[0:start_A])\n",
    "        if data_A_len - end_A >= n_frames and max(f0_A[end_A:]) > 0:\n",
    "            pool_A.append(data_A[:,end_A:])\n",
    "            f0s_A.append(f0_A[end_A:])\n",
    "        del pool_A[idx_A]\n",
    "        del f0s_A[idx_A]\n",
    " \n",
    "        start_B = np.random.randint(data_B_len - n_frames + 1)\n",
    "        end_B = start_B + n_frames\n",
    "        if max(f0_B[start_B:end_B]) > 0:\n",
    "            train_data_B.append(data_B[:,start_B:end_B])\n",
    "        if start_B >= n_frames and max(f0_B[0:start_B]) > 0:\n",
    "            pool_B.append(data_B[:,0:start_B])\n",
    "            f0s_B.append(f0_B[0:start_B])\n",
    "        if data_B_len - end_B >= n_frames and max(f0_B[end_B:]) > 0:\n",
    "            pool_B.append(data_B[:,end_B:])\n",
    "            f0s_B.append(f0_B[end_B:])\n",
    "        del pool_B[idx_B]\n",
    "        del f0s_B[idx_B]\n",
    "\n",
    "        # reach maximum data length\n",
    "        if len(train_data_A) >= max_samples:\n",
    "            break\n",
    "    \n",
    "    num = min(len(train_data_A), len(train_data_B))\n",
    "    np.random.shuffle(train_data_A)\n",
    "    np.random.shuffle(train_data_B)\n",
    "    train_data_A = np.array(train_data_A[0:num])\n",
    "    train_data_B = np.array(train_data_B[0:num])\n",
    "\n",
    "    return train_data_A, train_data_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_A, dataset_B = sample_train_data(pool_A=pool_A, pool_B=pool_B, n_frames=n_frames, max_samples=1000)\n",
    "dataset_A, dataset_B = sample_train_data2(pool_A=pool_A, pool_B=pool_B, f0s_A=f0sA, f0s_B=f0sB, n_frames=n_frames, max_samples=1000)\n",
    "print(np.shape(dataset_A), np.shape(dataset_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a, b = [1], [1]\n",
    "# c, d = list(a), list(b)\n",
    "# c.append(8)\n",
    "# print(a, b, c, d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## START Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = dataset_A.shape[0]\n",
    "print(n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load CycleGAN model (Generator, Discriminator and Loss functions)\n",
    "model = CycleGAN(num_features = num_mcep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train for 1 epoch\n",
    "epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_samples // mini_batch_size):\n",
    "\n",
    "    num_iterations = n_samples // mini_batch_size * epoch + i\n",
    "\n",
    "    if num_iterations > 10000:\n",
    "        lambda_identity = 0\n",
    "    if num_iterations > 200000:\n",
    "        generator_learning_rate = max(0, generator_learning_rate - generator_learning_rate_decay)\n",
    "        discriminator_learning_rate = max(0, discriminator_learning_rate - discriminator_learning_rate_decay)\n",
    "\n",
    "    start = i * mini_batch_size\n",
    "    end = (i + 1) * mini_batch_size\n",
    "\n",
    "    generator_loss, discriminator_loss = model.train(input_A = dataset_A[start:end], input_B = dataset_B[start:end], lambda_cycle = lambda_cycle, lambda_identity = lambda_identity, generator_learning_rate = generator_learning_rate, discriminator_learning_rate = discriminator_learning_rate)\n",
    "\n",
    "    if i % 50 == 0:\n",
    "        #print('Iteration: %d, Generator Loss : %f, Discriminator Loss : %f' % (num_iterations, generator_loss, discriminator_loss))\n",
    "        print('Iteration: {:07d}, Generator Learning Rate: {:.7f}, Discriminator Learning Rate: {:.7f}, Generator Loss : {:.3f}, Discriminator Loss : {:.3f}'.format(num_iterations, generator_learning_rate, discriminator_learning_rate, generator_loss, discriminator_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(directory = model_dir, filename = model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SET output dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "np.savez(os.path.join(model_dir, 'logf0s_normalization.npz'), mean_A = log_f0s_mean_A, std_A = log_f0s_std_A, mean_B = log_f0s_mean_B, std_B = log_f0s_std_B)\n",
    "np.savez(os.path.join(model_dir, 'mcep_normalization.npz'), mean_A = coded_sps_A_mean, std_A = coded_sps_A_std, mean_B = coded_sps_B_mean, std_B = coded_sps_B_std)\n",
    "\n",
    "if validation_A_dir is not None:\n",
    "    validation_A_output_dir = os.path.join(output_dir, 'converted_A')\n",
    "    if not os.path.exists(validation_A_output_dir):\n",
    "        os.makedirs(validation_A_output_dir)\n",
    "\n",
    "if validation_B_dir is not None:\n",
    "    validation_B_output_dir = os.path.join(output_dir, 'converted_B')\n",
    "    if not os.path.exists(validation_B_output_dir):\n",
    "        os.makedirs(validation_B_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if validation_A_dir is not None:\n",
    "    if epoch % 50 == 0:\n",
    "        print('Generating Validation Data B from A...')\n",
    "        for file in os.listdir(validation_A_dir):\n",
    "            filepath = os.path.join(validation_A_dir, file)\n",
    "            wav, _ = librosa.load(filepath, sr = sampling_rate, mono = True)\n",
    "            wav = wav_padding(wav = wav, sr = sampling_rate, frame_period = frame_period, multiple = 4)\n",
    "            f0, timeaxis, sp, ap = world_decompose(wav = wav, fs = sampling_rate, frame_period = frame_period)\n",
    "            f0_converted = pitch_conversion(f0 = f0, mean_log_src = log_f0s_mean_A, std_log_src = log_f0s_std_A, mean_log_target = log_f0s_mean_B, std_log_target = log_f0s_std_B)\n",
    "            coded_sp = world_encode_spectral_envelop(sp = sp, fs = sampling_rate, dim = num_mcep)\n",
    "            coded_sp_transposed = coded_sp.T\n",
    "            coded_sp_norm = (coded_sp_transposed - coded_sps_A_mean) / coded_sps_A_std\n",
    "            coded_sp_converted_norm = model.test(inputs = np.array([coded_sp_norm]), direction = 'A2B')[0]\n",
    "            coded_sp_converted = coded_sp_converted_norm * coded_sps_B_std + coded_sps_B_mean\n",
    "            coded_sp_converted = coded_sp_converted.T\n",
    "            coded_sp_converted = np.ascontiguousarray(coded_sp_converted)\n",
    "            decoded_sp_converted = world_decode_spectral_envelop(coded_sp = coded_sp_converted, fs = sampling_rate)\n",
    "            wav_transformed = world_speech_synthesis(f0 = f0_converted, decoded_sp = decoded_sp_converted, ap = ap, fs = sampling_rate, frame_period = frame_period)\n",
    "#             librosa.output.write_wav(os.path.join(validation_A_output_dir, os.path.basename(file)), wav_transformed, sampling_rate)\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "A = wav\n",
    "print(np.shape(A))\n",
    "librosa.display.waveplot(A, sr=sampling_rate)\n",
    "Audio(A, rate=sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X = librosa.stft(A)\n",
    "Xdb = librosa.amplitude_to_db(abs(X))\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.specshow(Xdb, sr=sampling_rate, x_axis='time', y_axis='hz')\n",
    "colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A2B = wav_transformed\n",
    "print(np.shape(A2B))\n",
    "librosa.display.waveplot(A2B, sr=sampling_rate)\n",
    "Audio(A2B, rate=sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = librosa.stft(A2B)\n",
    "Xdb = librosa.amplitude_to_db(abs(X))\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.specshow(Xdb, sr=sampling_rate, x_axis='time', y_axis='hz')\n",
    "colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if validation_B_dir is not None:\n",
    "    if epoch % 50 == 0:\n",
    "        print('Generating Validation Data A from B...')\n",
    "        for file in os.listdir(validation_B_dir):\n",
    "            filepath = os.path.join(validation_B_dir, file)\n",
    "            wav, _ = librosa.load(filepath, sr = sampling_rate, mono = True)\n",
    "            wav = wav_padding(wav = wav, sr = sampling_rate, frame_period = frame_period, multiple = 4)\n",
    "            f0, timeaxis, sp, ap = world_decompose(wav = wav, fs = sampling_rate, frame_period = frame_period)\n",
    "            f0_converted = pitch_conversion(f0 = f0, mean_log_src = log_f0s_mean_B, std_log_src = log_f0s_std_B, mean_log_target = log_f0s_mean_A, std_log_target = log_f0s_std_A)\n",
    "            coded_sp = world_encode_spectral_envelop(sp = sp, fs = sampling_rate, dim = num_mcep)\n",
    "            coded_sp_transposed = coded_sp.T\n",
    "            coded_sp_norm = (coded_sp_transposed - coded_sps_B_mean) / coded_sps_B_std\n",
    "            coded_sp_converted_norm = model.test(inputs = np.array([coded_sp_norm]), direction = 'B2A')[0]\n",
    "            coded_sp_converted = coded_sp_converted_norm * coded_sps_A_std + coded_sps_A_mean\n",
    "            coded_sp_converted = coded_sp_converted.T\n",
    "            coded_sp_converted = np.ascontiguousarray(coded_sp_converted)\n",
    "            decoded_sp_converted = world_decode_spectral_envelop(coded_sp = coded_sp_converted, fs = sampling_rate)\n",
    "            wav_transformed = world_speech_synthesis(f0 = f0_converted, decoded_sp = decoded_sp_converted, ap = ap, fs = sampling_rate, frame_period = frame_period)\n",
    "#             librosa.output.write_wav(os.path.join(validation_B_output_dir, os.path.basename(file)), wav_transformed, sampling_rate)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = wav\n",
    "print(np.shape(B))\n",
    "librosa.display.waveplot(B, sr=sampling_rate)\n",
    "Audio(B, rate=sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = librosa.stft(B)\n",
    "Xdb = librosa.amplitude_to_db(abs(X))\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.specshow(Xdb, sr=sampling_rate, x_axis='time', y_axis='hz')\n",
    "colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B2A = wav_transformed\n",
    "print(np.shape(B2A))\n",
    "librosa.display.waveplot(B2A, sr=sampling_rate)\n",
    "Audio(B2A, rate=sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = librosa.stft(B2A)\n",
    "Xdb = librosa.amplitude_to_db(abs(X))\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.specshow(Xdb, sr=sampling_rate, x_axis='time', y_axis='hz')\n",
    "colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test wav padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # def wav_padding(wav, sr, frame_period, multiple = 4):\n",
    "# # multiple=4 blocks, each block is 5ms with 0.005*16000=80 frames. \n",
    "# # minimum 4 bloacks, 4, 8, 12, ... \n",
    "# # after padding, frames: 560, 880, 1200, ...\n",
    "# num_frames = 280\n",
    "# sr = 16000\n",
    "# multiple = 4\n",
    "# num_frames_padded = int((np.ceil((np.floor(num_frames / (sr * frame_period / 1000)) + 1) / multiple + 1) * multiple - 1) * (sr * frame_period / 1000))\n",
    "# num_frames_diff = num_frames_padded - num_frames\n",
    "# num_pad_left = num_frames_diff // 2\n",
    "# num_pad_right = num_frames_diff - num_pad_left\n",
    "# print(num_pad_left, num_pad_left)\n",
    "# print(num_frames_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
